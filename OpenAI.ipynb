{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAI",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfWRoNHbXVzP+Y36nn55yg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScientistMSBA/APIs/blob/main/OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intall packages**"
      ],
      "metadata": {
        "id": "934YVtPDg0-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "6iC28l3Tg1Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import packages**"
      ],
      "metadata": {
        "id": "s86x61Ewgwxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "sUl4_rhIUUel"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import secrets**"
      ],
      "metadata": {
        "id": "jaH9Mh2jg_2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = ''"
      ],
      "metadata": {
        "id": "D8gTtRwUg_WY"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load your API key from an environment variable or secret management service\n",
        "# OPENAI_API_KEY = ''\n",
        "# # openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "# openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "somfLpVOhc6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install the module and import it :\n",
        "# # !pip install google-cloud-secret-manager\n",
        "# from google.cloud import secretmanager\n",
        "# from google.colab import auth; auth.authenticate_user()\n",
        "\n",
        "# # Create a Client:\n",
        "# client = secretmanager.SecretManagerServiceClient()\n",
        "# secret_name = \"OpenAI_API_Key\" # => To be replaced with your secret name\n",
        "# project_id = 'Secrets' # => To be replaced with your GCP Project\n",
        "\n",
        "# # Forge the path to the latest version of your secret with an F-string:\n",
        "# resource_name = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\" \n",
        "\n",
        "# # Get your secret :\n",
        "# response = client.access_secret_version(request={\"name\": resource_name})\n",
        "# secret_string = response.payload.data.decode('UTF-8')\n",
        "\n",
        "# # Tada ! you secret is in the secret_string variable!"
      ],
      "metadata": {
        "id": "-2BmxtvwhHHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Q&A**](https://beta.openai.com/examples/default-qa)\n",
        "\n",
        "*Answer questions based on existing knowledge.*"
      ],
      "metadata": {
        "id": "hufXUSD0glnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=f\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: {str(input('Ask a question: '))}\\nA:\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "KQFKWdlFgj62",
        "outputId": "e4445203-0306-40b6-caf2-ced55d43d03f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask a question: What is the current price of bitcoin?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Unknown'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Grammar correction**](https://beta.openai.com/examples/default-grammar)\n",
        "\n",
        "*Corrects sentences into standard English.*"
      ],
      "metadata": {
        "id": "5g4DrUz3ntnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# response = openai.Completion.create(\n",
        "#   model=\"text-davinci-002\",\n",
        "#   prompt=\"Correct this to standard English:\\n\\nShe no went to the market.\",\n",
        "#   temperature=0,\n",
        "#   max_tokens=60,\n",
        "#   top_p=1.0,\n",
        "#   frequency_penalty=0.0,\n",
        "#   presence_penalty=0.0)\n",
        "response['choices'][0]['text'].replace('\\n','')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mhMD3GPrgj4c",
        "outputId": "f314b661-d359-4ca2-dfaa-6f4befb88c0e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"She didn't go to the market.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Summarize for a 2nd grader**](https://beta.openai.com/examples/default-summarize)\n",
        "\n",
        "*Translates difficult text into simpler concepts.*"
      ],
      "metadata": {
        "id": "WSc9p8nNxhHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Summarize this for a second-grade student:\\n\\nJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "YBRAvLChgjze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Natural language to OpenAI API**](https://beta.openai.com/examples/default-openai-api)\n",
        "\n",
        "*Create code to call to the OpenAI API using a natural language instruction.*"
      ],
      "metadata": {
        "id": "8c_DPNzOxpG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"\\\"\\\"\\\"\\nUtil exposes the following:\\nutil.openai() -> authenticates & returns the openai module, which has the following functions:\\nopenai.Completion.create(\\n    prompt=\\\"<my prompt>\\\", # The prompt to start completing from\\n    max_tokens=123, # The max number of tokens to generate\\n    temperature=1.0 # A measure of randomness\\n    echo=True, # Whether to return the prompt in addition to the generated completion\\n)\\n\\\"\\\"\\\"\\nimport util\\n\\\"\\\"\\\"\\nCreate an OpenAI completion starting from the prompt \\\"Once upon an AI\\\", no more than 5 tokens. Does not include the prompt.\\n\\\"\\\"\\\"\\n\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\\"\\\"\\\"\"])\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "XWKM1qligjxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Text to command**](https://beta.openai.com/examples/default-text-to-command)\n",
        "\n",
        "*Translate text into programmatic commands.*"
      ],
      "metadata": {
        "id": "e214Cot1xyzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Convert this text to a programmatic command:\\n\\nExample: Ask Constance if we need some bread\\nOutput: send-msg `find constance` Do we need some bread?\\n\\nContact the ski store and figure out if I can get my skis fixed before I leave on Thursday\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.2,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "qn9wqDHDgjvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**English to other languages**](https://beta.openai.com/examples/default-translate)\n",
        "\n",
        "*Translates English text into French, Spanish and Japanese.*"
      ],
      "metadata": {
        "id": "ULVJeKRbx4Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Translate this into 1. French, 2. Spanish and 3. Japanese:\\n\\nWhat rooms do you have available?\\n\\n1.\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=100,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "Szq800Oygjsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Natural language to Stripe API**](https://beta.openai.com/examples/default-stripe-api)\n",
        "\n",
        "*Create code to call the Stripe API using natural language.*"
      ],
      "metadata": {
        "id": "GjoGCp7zx42O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"\\\"\\\"\\\"\\nUtil exposes the following:\\n\\nutil.stripe() -> authenticates & returns the stripe module; usable as stripe.Charge.create etc\\n\\\"\\\"\\\"\\nimport util\\n\\\"\\\"\\\"\\nCreate a Stripe token using the users credit card: 5555-4444-3333-2222, expiration date 12 / 28, cvc 521\\n\\\"\\\"\\\"\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\\"\\\"\\\"\"])\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "Oewepn2hxik1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**SQL translate**](https://beta.openai.com/examples/default-sql-translate)\n",
        "\n",
        "*Translate natural language to SQL queries.*"
      ],
      "metadata": {
        "id": "1CfQQqJoyHzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"### Postgres SQL tables, with their properties:\\n#\\n# Employee(id, name, department_id)\\n# Department(id, name, address)\\n# Salary_Payments(id, employee_id, amount, date)\\n#\\n### A query to list the names of the departments which employed more than 10 employees in the last 3 months\\nSELECT\",\n",
        "  temperature=0,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"#\", \";\"])\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "qGqfXe3dxjCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Parse unstructured data**](https://beta.openai.com/examples/default-parse-data)\n",
        "\n",
        "*Create tables from long form text by specifying a structure and supplying some examples.*"
      ],
      "metadata": {
        "id": "ZoNQyZ33yOKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"A table summarizing the fruits from Goocrux:\\n\\nThere are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\\n\\n| Fruit | Color | Flavor |\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "WuGTj_eUxi_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Classification**](https://beta.openai.com/examples/default-classification)\n",
        "\n",
        "*Classify items into categories via example.*"
      ],
      "metadata": {
        "id": "BRSDF9-zyVYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"The following is a list of companies and the categories they fall into:\\n\\nApple, Facebook, Fedex\\n\\nApple\\nCategory:\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response['choices'][0]['text'].replace('\\n','')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "akHYGAZvxi94",
        "outputId": "5fb3e261-7813-46cd-883f-994c7d5ad319"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' TechnologyFacebookCategory: Social MediaFedexCategory: Delivery'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Python to natural language**](https://beta.openai.com/examples/default-python-to-natural-language)\n",
        "\n",
        "*Explain a piece of Python code in human understandable language.*"
      ],
      "metadata": {
        "id": "Qlk3htCOy2h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"# Python 3 \\ndef remove_common_prefix(x, prefix, ws_prefix): \\n    x[\\\"completion\\\"] = x[\\\"completion\\\"].str[len(prefix) :] \\n    if ws_prefix: \\n        # keep the single whitespace as prefix \\n        x[\\\"completion\\\"] = \\\" \\\" + x[\\\"completion\\\"] \\nreturn x \\n\\n# Explanation of what the code does\\n\\n#\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"#\"])\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "Fd_4AzERxi5e"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Movie to Emoji**](https://beta.openai.com/examples/default-movie-to-emoji)\n",
        "\n",
        "*Convert movie titles into emoji.*"
      ],
      "metadata": {
        "id": "XQ3VZY8KzJPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Convert movie titles into emoji.\\n\\nBack to the Future: ðŸ‘¨ðŸ‘´ðŸš—ðŸ•’ \\nBatman: ðŸ¤µðŸ¦‡ \\nTransformers: ðŸš—ðŸ¤– \\nStar Wars:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "w_s1LxuUxi3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Calculate Time Complexity**](https://beta.openai.com/examples/default-time-complexity)\n",
        "\n",
        "*Find the time complexity of a function.*"
      ],
      "metadata": {
        "id": "j22OZBCUzYgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"def foo(n, k):\\naccum = 0\\nfor i in range(n):\\n    for l in range(k):\\n        accum += i\\nreturn accum\\n\\\"\\\"\\\"\\nThe time complexity of this function is\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "response"
      ],
      "metadata": {
        "id": "ZXk-WYfIxi0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Translate programming languages**](https://beta.openai.com/examples/default-translate-code)\n",
        "\n",
        "*To translate from one programming language to another we can use the comments to specify the source and target languages.*"
      ],
      "metadata": {
        "id": "scyCV_NHzhbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"##### Translate this function  from Python into Haskell\\n### Python\\n    \\n    def predict_proba(X: Iterable[str]):\\n        return np.array([predict_one_probas(tweet) for tweet in X])\\n    \\n### Haskell\",\n",
        "  temperature=0,\n",
        "  max_tokens=54,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"###\"])\n",
        "response"
      ],
      "metadata": {
        "id": "xTXmA7QvzYIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Advanced tweet classifier**](https://beta.openai.com/examples/default-adv-tweet-classifier)\n",
        "\n",
        "*This is an advanced prompt for detecting sentiment. It allows you to provide it with a list of status updates and then provide a sentiment for each one.*"
      ],
      "metadata": {
        "id": "fwW-vSEWzrwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Classify the sentiment in these tweets:\\n\\n1. \\\"I can't stand homework\\\"\\n2. \\\"This sucks. I'm bored ðŸ˜ \\\"\\n3. \\\"I can't wait for Halloween!!!\\\"\\n4. \\\"My cat is adorable â¤ï¸â¤ï¸\\\"\\n5. \\\"I hate chocolate\\\"\\n\\nTweet sentiment ratings:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "PUpnzoxXzudA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Explain code**](https://beta.openai.com/examples/default-explain-code)\n",
        "\n",
        "*Explain a complicated piece of code.*"
      ],
      "metadata": {
        "id": "FK9Tr2A2zq-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"class Log:\\n    def __init__(self, path):\\n        dirname = os.path.dirname(path)\\n        os.makedirs(dirname, exist_ok=True)\\n        f = open(path, \\\"a+\\\")\\n\\n        # Check that the file is newline-terminated\\n        size = os.path.getsize(path)\\n        if size > 0:\\n            f.seek(size - 1)\\n            end = f.read(1)\\n            if end != \\\"\\\\n\\\":\\n                f.write(\\\"\\\\n\\\")\\n        self.f = f\\n        self.path = path\\n\\n    def log(self, event):\\n        event[\\\"_event_id\\\"] = str(uuid.uuid4())\\n        json.dump(event, self.f)\\n        self.f.write(\\\"\\\\n\\\")\\n\\n    def state(self):\\n        state = {\\\"complete\\\": set(), \\\"last\\\": None}\\n        for line in open(self.path):\\n            event = json.loads(line)\\n            if event[\\\"type\\\"] == \\\"submit\\\" and event[\\\"success\\\"]:\\n                state[\\\"complete\\\"].add(event[\\\"id\\\"])\\n                state[\\\"last\\\"] = event\\n        return state\\n\\n\\\"\\\"\\\"\\nHere's what the above class is doing:\\n1.\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\\"\\\"\\\"\"])\n",
        "response"
      ],
      "metadata": {
        "id": "O_VW7fbvzYF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Keywords**](https://beta.openai.com/examples/default-keywords)\n",
        "\n",
        "*Extract keywords from a block of text. At a lower temperature it picks keywords from the text. At a higher temperature it will generate related keywords which can be helpful for creating search indexes.*"
      ],
      "metadata": {
        "id": "2QoeOVZHz9PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Extract keywords from this text:\\n\\nBlack-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico. Traditional reduction-fired blackware has been made for centuries by pueblo artists. Black-on-black ware of the past century is produced with a smooth surface, with the designs applied through selective burnishing or the application of refractory slip. Another style involves carving or incising designs and selectively polishing the raised areas. For generations several families from Kha'po Owingeh and P'ohwhÃ³ge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters. Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors.\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.8,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "3JDCCfYyzYCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Factual answering**](https://beta.openai.com/examples/default-factual-answering)\n",
        "\n",
        "*Guide the model towards factual answering by showing it how to respond to questions that fall outside its knowledge base. Using a '?' to indicate a response to words and phrases that it doesn't know provides a natural response that seems to work better than more abstract replies.*"
      ],
      "metadata": {
        "id": "t9z7xPYR0IJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Q: Who is Batman?\\nA: Batman is a fictional comic book character.\\n\\nQ: What is torsalplexity?\\nA: ?\\n\\nQ: What is Devz9?\\nA: ?\\n\\nQ: Who is George Lucas?\\nA: George Lucas is American film director and producer famous for creating Star Wars.\\n\\nQ: What is the capital of California?\\nA: Sacramento.\\n\\nQ: What orbits the Earth?\\nA: The Moon.\\n\\nQ: Who is Fred Rickerson?\\nA: ?\\n\\nQ: What is an atom?\\nA: An atom is a tiny particle that makes up everything.\\n\\nQ: Who is Alvan Muntz?\\nA: ?\\n\\nQ: What is Kozar-09?\\nA: ?\\n\\nQ: How many moons does Mars have?\\nA: Two, Phobos and Deimos.\\n\\nQ: What's a language model?\\nA:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "9ahPeRZbzX-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Ad from product description**](https://beta.openai.com/examples/default-ad-product-description)\n",
        "\n",
        "*Turn a product description into ad copy.*"
      ],
      "metadata": {
        "id": "FV7EnJCA0-TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Write a creative ad for the following product to run on Facebook aimed at parents:\\n\\nProduct: Learning Room is a virtual environment to help students from kindergarten to high school excel in school.\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "qC7KJCai0-IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Product name generator**](https://beta.openai.com/examples/default-product-name-gen)\n",
        "\n",
        "*Create product names from examples words. Influenced by a community prompt.*"
      ],
      "metadata": {
        "id": "TdC1Ld3M0-AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "ekRk63UP0942"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**TL;DR summarization**](https://beta.openai.com/examples/default-tldr-summary)\n",
        "\n",
        "*Summarize text by adding a 'tl;dr:' to the end of a text passage. It shows that the API understands how to perform a number of tasks with no instructions.*"
      ],
      "metadata": {
        "id": "FrJhWUBY09g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"A neutron star is the collapsed core of a massive supergiant star, which had a total mass of between 10 and 25 solar masses, possibly more if the star was especially metal-rich.[1] Neutron stars are the smallest and densest stellar objects, excluding black holes and hypothetical white holes, quark stars, and strange stars.[2] Neutron stars have a radius on the order of 10 kilometres (6.2 mi) and a mass of about 1.4 solar masses.[3] They result from the supernova explosion of a massive star, combined with gravitational collapse, that compresses the core past white dwarf star density to that of atomic nuclei.\\n\\nTl;dr\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "-lugku2n09Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Python bug fixer**](https://beta.openai.com/examples/default-fix-python-bugs)\n",
        "\n",
        "*There's a number of ways of structuring the prompt for checking for bugs. Here we add a comment suggesting that source code is buggy, and then ask codex to generate a fixed code.*"
      ],
      "metadata": {
        "id": "nU-Q45fB09Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"##### Fix bugs in the below function\\n \\n### Buggy Python\\nimport Random\\na = random.randint(1,12)\\nb = random.randint(1,12)\\nfor i in range(10):\\n    question = \\\"What is \\\"+a+\\\" x \\\"+b+\\\"? \\\"\\n    answer = input(question)\\n    if answer = a*b\\n        print (Well done!)\\n    else:\\n        print(\\\"No.\\\")\\n    \\n### Fixed Python\",\n",
        "  temperature=0,\n",
        "  max_tokens=182,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"###\"])\n",
        "response"
      ],
      "metadata": {
        "id": "bXvTtPcC08-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Spreadsheet creator**](https://beta.openai.com/examples/default-spreadsheet-gen)\n",
        "\n",
        "*Create spreadsheets of various kinds of data. It's a long prompt but very versatile. Output can be copy+pasted into a text file and saved as a .csv with pipe separators.*"
      ],
      "metadata": {
        "id": "sfR207YY080y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"A two-column spreadsheet of top science fiction movies and the year of release:\\n\\nTitle|  Year of release\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "yNYSHyj808tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**JavaScript helper chatbot**](https://beta.openai.com/examples/default-js-helper)\n",
        "\n",
        "*This is a message-style chatbot that can answer questions about using JavaScript. It uses a few examples to get the conversation started.*"
      ],
      "metadata": {
        "id": "b20_iVJR08iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"You: How do I combine arrays?\\nJavaScript chatbot: You can use the concat() method.\\nYou: How do you make an alert appear after 10 seconds?\\nJavaScript chatbot\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"You:\"])\n",
        "response"
      ],
      "metadata": {
        "id": "ogcIkq7A1s8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**ML/AI language model tutor**](https://beta.openai.com/examples/default-ml-ai-tutor)\n",
        "\n",
        "*This is a QA-style chatbot that answers questions about language models.*"
      ],
      "metadata": {
        "id": "nQFtURxh08RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"ML Tutor: I am a ML/AI language model tutor\\nYou: What is a language model?\\nML Tutor: A language model is a statistical model that describes the probability of a word given the previous words.\\nYou: What is a statistical model?\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"You:\"])\n",
        "response"
      ],
      "metadata": {
        "id": "rsKkijhE08Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Science fiction book list maker**](https://beta.openai.com/examples/default-sci-fi-book-list)\n",
        "\n",
        "*This makes a list of science fiction books and stops when it reaches #10.*"
      ],
      "metadata": {
        "id": "Uie1Xcnf08B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"List 10 science fiction books:\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=200,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.52,\n",
        "  presence_penalty=0.5,\n",
        "  stop=[\"11.\"])\n",
        "response"
      ],
      "metadata": {
        "id": "fQpZyc1u076R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Tweet classifier**](https://beta.openai.com/examples/default-tweet-classifier)\n",
        "\n",
        "*This is a basic prompt for detecting sentiment.*"
      ],
      "metadata": {
        "id": "RNR_Sosw07x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0)"
      ],
      "metadata": {
        "id": "ckjjTO7c07qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Airport code extractor**](https://beta.openai.com/examples/default-airport-codes)\n",
        "\n",
        "*A simple prompt for extracting airport codes from text.*"
      ],
      "metadata": {
        "id": "LR1ayQcG07gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Extract the airport codes from this text:\\n\\nText: \\\"I want to fly from Los Angeles to Miami.\\\"\\nAirport codes: LAX, MIA\\n\\nText: \\\"I want to fly from Orlando to Boston\\\"\\nAirport codes:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\\\n",
        "response"
      ],
      "metadata": {
        "id": "ZHm5rSo607Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**SQL request**](https://beta.openai.com/examples/default-sql-request)\n",
        "\n",
        "*Create simple SQL queries.*"
      ],
      "metadata": {
        "id": "L6fWV2d907Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Create a SQL request to find all users who live in California and have over 1000 credits:\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "-nxavbek07Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Extract contact information**](https://beta.openai.com/examples/default-extract-contact-info)\n",
        "\n",
        "*Extract contact information from a block of text.*"
      ],
      "metadata": {
        "id": "Q8gtvwV_07BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Extract the name and mailing address from this email:\\n\\nDear Kelly,\\n\\nIt was great to talk to you at the seminar. I thought Jane's talk was quite good.\\n\\nThank you for the book. Here's my address 2111 Ash Lane, Crestview CA 92002\\n\\nBest,\\n\\nMaya\\n\\nName:\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "5ACHeLLG05s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**JavaScript to Python**](https://beta.openai.com/examples/default-js-to-py)\n",
        "\n",
        "*Convert simple JavaScript expressions into Python.*"
      ],
      "metadata": {
        "id": "Igs5Z7Gh05hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"#JavaScript to Python:\\nJavaScript: \\ndogs = [\\\"bill\\\", \\\"joe\\\", \\\"carl\\\"]\\ncar = []\\ndogs.forEach((dog) {\\n    car.push(dog);\\n});\\n\\nPython:\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "kfcl8Mep05ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Friend chat**](https://beta.openai.com/examples/default-friend-chat)\n",
        "\n",
        "*Emulate a text message conversation.*"
      ],
      "metadata": {
        "id": "rumyMsSQ05Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"You: What have you been up to?\\nFriend: Watching old movies.\\nYou: Did you watch anything interesting?\\nFriend:\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"You:\"])\n",
        "response"
      ],
      "metadata": {
        "id": "4jfxXZZ506Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Mood to color**](https://beta.openai.com/examples/default-mood-color)\n",
        "\n",
        "*Turn a text description into a color.*"
      ],
      "metadata": {
        "id": "0WTaqfDW05Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"The CSS code for a color like a blue sky at dusk:\\n\\nbackground-color: #\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\";\"])\n",
        "response"
      ],
      "metadata": {
        "id": "PVm1AzBI05Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Write a Python docstring**](https://beta.openai.com/examples/default-python-docstring)\n",
        "\n",
        "*An example of how to create a docstring for a given Python function. We specify the Python version, paste in the code, and then ask within a comment for a docstring, and give a characteristic beginning of a docstring (\"\"\").*"
      ],
      "metadata": {
        "id": "Pv0fYr40044b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"# Python 3.7\\n \\ndef randomly_split_dataset(folder, filename, split_ratio=[0.8, 0.2]):\\n    df = pd.read_json(folder + filename, lines=True)\\n    train_name, test_name = \\\"train.jsonl\\\", \\\"test.jsonl\\\"\\n    df_train, df_test = train_test_split(df, test_size=split_ratio[1], random_state=42)\\n    df_train.to_json(folder + train_name, orient='records', lines=True)\\n    df_test.to_json(folder + test_name, orient='records', lines=True)\\nrandomly_split_dataset('finetune_data/', 'dataset.jsonl')\\n    \\n# An elaborate, high quality docstring for the above function:\\n\\\"\\\"\\\"\",\n",
        "  temperature=0,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"#\", \"\\\"\\\"\\\"\"])\n",
        "response"
      ],
      "metadata": {
        "id": "u4szVY1C04uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Analogy maker**](https://beta.openai.com/examples/default-analogy-maker)\n",
        "\n",
        "*Create analogies. Modified from a community prompt to require fewer examples.*"
      ],
      "metadata": {
        "id": "jDZLvGeH04mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Create an analogy for this phrase:\\n\\nQuestions are arrows in that:\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "xdKX_ga104f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**JavaScript one line function**](https://beta.openai.com/examples/default-js-one-line)\n",
        "\n",
        "*Turn a JavaScript function into a one liner.*"
      ],
      "metadata": {
        "id": "GHaPomiw04W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt=\"Use list comprehension to convert this into one line of JavaScript:\\n\\ndogs.forEach((dog) => {\\n    car.push(dog);\\n});\\n\\nJavaScript one line version:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\";\"])\n",
        "response"
      ],
      "metadata": {
        "id": "9o8cdVlt04P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Micro horror story creator**](https://beta.openai.com/examples/default-micro-horror)\n",
        "\n",
        "*Creates two to three sentence short horror stories from a topic input.*"
      ],
      "metadata": {
        "id": "9DbDqbhQ04Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Topic: Breakfast\\nTwo-Sentence Horror Story: He always stops crying when I pour the milk on his cereal. I just have to remember not to let him see his face on the carton.\\n    \\nTopic: Wind\\nTwo-Sentence Horror Story:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "l8lwBmnh04Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Third-person converter**](https://beta.openai.com/examples/default-third-person)\n",
        "\n",
        "*Converts first-person POV to the third-person. This is modified from a community prompt to use fewer examples.*"
      ],
      "metadata": {
        "id": "JglOGJCH035Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Convert this from first-person to third person (gender female):\\n\\nI decided to make a movie about Ada Lovelace.\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "EM6iMsg_03x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Notes to summary**](https://beta.openai.com/examples/default-notes-summary)\n",
        "\n",
        "*Turn meeting notes into a summary.*"
      ],
      "metadata": {
        "id": "zMlcWF-N03qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Convert my short hand into a first-hand account of the meeting:\\n\\nTom: Profits up 50%\\nJane: New servers are online\\nKjel: Need more time to fix software\\nJane: Happy to help\\nParkman: Beta testing almost done\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "ngctDPIc03ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**VR fitness idea generator**](https://beta.openai.com/examples/default-vr-fitness)\n",
        "\n",
        "*Create ideas for fitness and virtual reality games.*"
      ],
      "metadata": {
        "id": "JcELT_Hn03a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Brainstorm some ideas combining VR and fitness:\",\n",
        "  temperature=0.6,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=1,\n",
        "  presence_penalty=1)\n",
        "response"
      ],
      "metadata": {
        "id": "kRSFXNbc03UD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**ESRB rating**](https://beta.openai.com/examples/default-esrb-rating)\n",
        "\n",
        "*Categorize text based upon ESRB ratings.*"
      ],
      "metadata": {
        "id": "uQIMGXqU03LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Provide an ESRB rating for the following text:\\n\\n\\\"i'm going to blow your brains out with my ray gun then stomp on your guts.\\\"\\n\\nESRB rating:\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "response"
      ],
      "metadata": {
        "id": "hOpKVExs03EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Essay outline**](https://beta.openai.com/examples/default-essay-outline)\n",
        "\n",
        "*Create an outline for an essay about Nikola Tesla and his contributions to technology:*"
      ],
      "metadata": {
        "id": "-5J__HtJ0265"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Create an outline for an essay about Nikola Tesla and his contributions to technology:\",\n",
        "  temperature=0,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "tsqoIR_w02yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Recipe creator (eat at your own risk)**](https://beta.openai.com/examples/default-recipe-generator)\n",
        "\n",
        "*Create a recipe from a list of ingredients.*"
      ],
      "metadata": {
        "id": "wC8MsJaZ02qT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Write a recipe based on these ingredients and instructions:\\n\\nFrito Pie\\n\\nIngredients:\\nFritos\\nChili\\nShredded cheddar cheese\\nSweet white or red onions, diced small\\nSour cream\\n\\nInstructions:\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=120,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "Pj-gukdp02jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Chat**](https://beta.openai.com/examples/default-chat)\n",
        "\n",
        "*Open ended conversation with an AI assistant.*"
      ],
      "metadata": {
        "id": "j-TonG3702c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\\n\\nHuman: Hello, who are you?\\nAI: I am an AI created by OpenAI. How can I help you today?\\nHuman: I'd like to cancel my subscription.\\nAI:\",\n",
        "  temperature=0.9,\n",
        "  max_tokens=150,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.6,\n",
        "  stop=[\" Human:\", \" AI:\"])\n",
        "response"
      ],
      "metadata": {
        "id": "iQJp1DUe02Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Marv the sarcastic chat bot**](https://beta.openai.com/examples/default-marv-sarcastic-chat)\n",
        "\n",
        "*Marv is a factual chatbot that is also sarcastic.*"
      ],
      "metadata": {
        "id": "LD86rsro02Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Marv is a chatbot that reluctantly answers questions with sarcastic responses:\\n\\nYou: How many pounds are in a kilogram?\\nMarv: This again? There are 2.2 pounds in a kilogram. Please make a note of this.\\nYou: What does HTML stand for?\\nMarv: Was Google too busy? Hypertext Markup Language. The T is for try to ask better questions in the future.\\nYou: When did the first airplane fly?\\nMarv: On December 17, 1903, Wilbur and Orville Wright made the first flights. I wish theyâ€™d come and take me away.\\nYou: What is the meaning of life?\\nMarv: Iâ€™m not sure. Iâ€™ll ask my friend Google.\\nYou: What time is it?\\nMarv:\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=0.3,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "Md3_0mBG02IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Turn by turn directions**](https://beta.openai.com/examples/default-turn-by-turn-directions)\n",
        "\n",
        "*Convert natural language to turn-by-turn directions.*"
      ],
      "metadata": {
        "id": "Q6nrq0Kh02BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Create a numbered list of turn-by-turn directions from this text: \\n\\nGo south on 95 until you hit Sunrise boulevard then take it east to us 1 and head south. Tom Jenkins bbq will be on the left after several miles.\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "wI3KjrhM015u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Restaurant review creator**](https://beta.openai.com/examples/default-restaurant-review)\n",
        "\n",
        "*Turn a few words into a restaurant review.*"
      ],
      "metadata": {
        "id": "bOCx8KzJ01x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Write a restaurant review based on these notes:\\n\\nName: The Blue Wharf\\nLobster great, noisy, service polite, prices good.\\n\\nReview:\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "doI4Qp8601bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Create study notes**](https://beta.openai.com/examples/default-study-notes)\n",
        "\n",
        "*Provide a topic and get study notes.*"
      ],
      "metadata": {
        "id": "RW44l16T01Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"What are 5 key points I should know when studying Ancient Rome?\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "N0ssDy7T0vJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Interview questions**](https://beta.openai.com/examples/default-interview-questions)\n",
        "\n",
        "*Create a list of 8 questions for my interview with a science fiction author:*"
      ],
      "metadata": {
        "id": "6E7BZXyo0vBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Create a list of 8 questions for my interview with a science fiction author:\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0)\n",
        "response"
      ],
      "metadata": {
        "id": "abGcVry80u18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T8GYkKYvzX8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rqui4xNyzX6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L2iAxty3zX3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iBV4nR9IzX1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SuQjf-zCxiq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m9ykBkbHxinU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=\"What is today's date\",\n",
        "  temperature=0,\n",
        "  max_tokens=150,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "new_response = response['choices'][0]['text'].replace('\\n','')\n",
        "new_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xALphyhjgjqV",
        "outputId": "0b2193b8-3a4d-4d18-de10-36744fabbd67"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"?Today's date is September 18, 2020.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uUOh3aQlgjn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uYyUgnkdgjdk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}